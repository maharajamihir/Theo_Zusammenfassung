% Created 2022-06-09 Thu 17:35
% Intended LaTeX compiler: pdflatex
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\author{Ali, Mihir, Noah}
\date{\today}
\title{Einführung in die Theoretische Informatik Zusammenfassung}
\hypersetup{
 pdfauthor={Ali, Mihir, Noah},
 pdftitle={Einführung in die Theoretische Informatik Zusammenfassung},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 28.1 (Org mode 9.6)}, 
 pdflang={English}}
\begin{document}

\maketitle
\tableofcontents


\section{Formale Sprachen}
\label{sec:org34df31a}

\subsection{Grundbegriffe}
\label{sec:org2b6c63c}
\begin{itemize}
\item Alphabet \(\Sigma\) (endliche Menge) z.B. \(\{1,0\}\)
\item Wort/String über \(\Sigma\) ist eine endliche Folge von Zeichen aus \(\Sigma\)
\item \(|w|\) länge des Wortes \(w\)
\item Leeres Wort \(\epsilon\)
\item \(uv\) konkatenation der Wörter \(u\) und \(w\)
\item Ist \(w\) ein Wort so ist \(w^0 = \epsilon\) und \(w^{n+1} = ww^n\)
\item \(\Sigma^*\) Menge aller Wörter über \(\Sigma\)
\item (formale) Sprache \(L \subseteq \Sigma^*\)
\end{itemize}

\subsubsection{Operationen auf Sprachen}
\label{sec:org8dd4fbe}
Seien \(A,B \subseteq \Sigma^*\)
\begin{itemize}
\item Konkatenation:
\end{itemize}
\(AB = \{uv | u \in A \land v \in B \}\)
\begin{itemize}
\item Konkatenation mit sich selbst:
\end{itemize}
\(A^n = \{w_1 ... w_n | w_1, ... , w_n \in A\} = A ... A\)
\begin{itemize}
\item \(A^* = \{w_1...w_n | n \geq 0 \land w_1, ... , w_n \in A\} = \bigcup_{n\in \mathbb{N}} A^n\)
\item \(A^+ = AA^* = \bigcup_{n \geq 1} A^n\)
\end{itemize}
\begin{enumerate}
\item Sonderfälle:
\label{sec:org6d9f786}
\begin{itemize}
\item \(\forall A: \epsilon \in A^*\)
\item \(\emptyset^* = \{\epsilon\}\)
\item \(\emptyset A = \emptyset\)
\item \(\{\epsilon \} A = A\)
\item \(A^*A^* = A^* = (A^*)^*\)
\end{itemize}
\end{enumerate}

\subsubsection{Grammatiken}
\label{sec:org46c95cc}
4-Tupel \(G = (V,\Sigma,P,S)\)
\begin{itemize}
\item \(V\) ist endliche Menge von Nichtterminalzeichen
\item \(\Sigma\) ist endliche Menga von Terminalzeichen (= Alphabet)
\item \(P \subseteq (V \cup \Sigma)^* \times (V \cup \Sigma)^*\) ist Menge von Produktionen
\item \(S \in V\) ist das Startsymbol
\end{itemize}

Die Sprache von G ist die Menge aller Wörter, die von G erzeugt werden. Sie wird mit \(L(G)\) bezeichnet.
Also jedes Wort, dass die Grammatik erzeugt muss in der Sprache erhalten sein und jedes Wort in der Sprache muss von der Grammatik erzeugt werden.
\begin{enumerate}
\item Reflexve transitive Hülle
\label{sec:orgda960da}

\begin{itemize}
\item \(\alpha \rightarrow^0_G \alpha\)
\item \(\alpha \rightarrow^{n+1}_G \gamma: \exists \beta. \alpha \rightarrow^n_G \rightarrow_G \gamma\)
\item \(\alpha \rightarrow^{*}_G \beta : \exists n. \alpha \rightarrow^n_G \beta\)
\item \(\alpha \rightarrow^{+}_G \beta: \exists n>0. \alpha \rightarrow^n_G \beta\)
\end{itemize}
\end{enumerate}

\subsubsection{Chomsky Hierarchie}
\label{sec:org0841dd4}
Eine Grammatik G ist vom
\begin{itemize}
\item Typ 0 immer
\item Typ 1 falls fpr jede Produktion \(\alpha \rightarrow \beta\) außer \(S \rightarrow \epsilon\) gilt \(|\alpha| \leq |\beta|\)
\item Typ 2 Falls G vom typ 1 ist und für jede Produktion \(\alpha \righarrow \beta\) gilt \(\alpha \in V\)
\item Typ 3 falls G vom Typ 2 ist und für jede Produktion \(\alpha \rightarrow \beta\) außer \(S \rightarrow \epsilon\) gilt \(\beta \in \Sigma \cup \Sigma V\)
\end{itemize}

\begin{enumerate}
\item Grmmatiken und Sprachklassen:
\label{sec:org776bb16}
\begin{center}
\begin{tabular}{lll}
Typ 3 & Rechtslineare Grammatiken & Reguläre Sprachen\\
Typ 2 & Kontextfreie Grammatik & Kontextfreie Sprachen\\
Typ 1 & Kontextsensitive Grammatik & Kontextsens. Sprachen\\
Typ 0 & Phrasenstrukturgrammatik & Rekursiv aufzählbare Sprachen\\
\end{tabular}
\end{center}

\item Satz 2.13
\label{sec:org9713596}
\(L(Typ 3) \subset L(Typ 2) \subset L(Typ 1) \subset L(Typ 0)\)
\end{enumerate}

\subsubsection{Wortproblem}
\label{sec:org1a34fde}
Gegeben: eine Grammatik G, ein Wort \(w \in \Sigma^*\)
Frage: Ist das Wort in w enthalten (\(w \in L(G)\))?

\section{Reguläre Sprachen}
\label{sec:org4dbf42a}

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./img/2-kapitel/reguläre_sprachen.png}
\caption{Reguläre Sprachen Schema}
\end{figure}

\subsection{Deterministische endliche Automaten}
\label{sec:org3a5d50b}
\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./img/2-kapitel/automat_bsp.png}
\caption{Beispiel Automat}
\end{figure}

\begin{itemize}
\item Beispiel:
\begin{itemize}
\item Eingabewort \(baba \rightarrow\) Zustandsfolge 0,0,1,2,2
\end{itemize}
\item ``Bei dieser Grammatik muss mindestens nach einem a ein b kommen''
\item Die Sprache des DFA ist die Menge aller Wörter über \(\{a,b\}\), die ab enthalten
\end{itemize}

Erkannte Sprache: Menge der Wörter, die vom Startzustand in einen Endzustand führen.
Recognizer, die nur einmal das Wort durchläuft und in linearer Zeit es akzeptiert oder ablehnt.

\subsubsection{Definition}
\label{sec:orgb310b45}
Ein deterministischer endlicher Automat \(M = (Q,\Sigma, \delta, q_0, F)\) besteht aus
\begin{itemize}
\item endliche Menge von Zuständen Q
\item endlichem Eingabealphabet \(\Sigma\)
\item einer totalen Übergangsfunktion \(\delta: Q \times \Sigma \rightarrow Q\)
\item eienm Startzustand \(q_0 \in Q\)
\item einer Menge \(F \subset Q\) von Endzuständen
\end{itemize}

\begin{enumerate}
\item Akzeptierte Sprachen (Definition 3.2)
\label{sec:org19ed369}
Von M akzeptierte Sprache \(L(M) := \{w \in \Sigma^* | \hat{\delta}(q_0, w) \in F\}\) wobei \\
\(\hat{\delta}: Q \times \Sigma^* \rightarrow Q\) induktiv definiert ist: \\
\(\hat{\delta}(q,\epsilon) = q\) \\
\(\hat{\delta}(q,aw) = \hat{\delta}(\delta(q,a),w)\), für \(a \in \Sigma, w \in \Sigma^*\) \\
(\(\hat{\delta}(q, w)\) bezeichnet den Zustand, den man aus \(q\) mit \(w\) erreicht.)\\
Eine Sprache ist regulär \textbf{gdw} sie von einem DFA akzeptiert wird.

\item Beispiel Automat der Sprache akzeptiert
\label{sec:org90fb277}
Induktiv beweisen pro Zustand.
\end{enumerate}


\subsection{Von rechtslinearen Grammatiken zu DFA}
\label{sec:orga47bb6e}
\begin{itemize}
\item Für jede rechtslineare Grammatik \(G\) gibt es einen DFA \(M\) mit \(L(M) = L(G)\)
\item Für jeden DFA \(M\) gibt es eine rechtslineare Grammatik \(G\) mit \(L(G) = L(M)\)
\end{itemize}

\subsubsection{Nichtdeterministischer endlicher Automat}
\label{sec:org8119e52}
Ein deterministischer endlicher Automat \(M = (Q,\Sigma, \delta, q_0, F)\) besteht aus
\begin{itemize}
\item \(Q, \Sigma, q_0, F\) sind wie DFA
\item \(\delta: Q \times \Sigma \rightarrow P(Q)\) \\
\(P(Q)\) = Menge aller Teilmengen von \(Q = 2^Q\) \\
Alternative: Relation \(\delta \subseteq Q \times \Sigma \times Q\)
\end{itemize}


\(\bar{\delta}(S,a) := \bigcup_{q \in S} \delta(q,a)\)


Es folgt: \(\hat{\bar{\delta}}: P(Q) \times \Sigma^* \rightarrow P(Q)\)

\begin{enumerate}
\item Intuition:
\label{sec:orga39d1f8}
\(\hat{\bar{\delta}}(S,w)\) ist Menge aller Zustände, die sich von einem Zustand in S aus \(w\) erreichen lassen.

\item Von nichtdeterminitsichen Automaten N akzeptierte Sprache
\label{sec:org0b75bf0}
\(L(N) := \{w \in \Sigma^* | \hat{\bar{\delta}}(\{q_0\},w) \cap F \neq \emptyset\}\)
\end{enumerate}

\subsubsection{Satz 3.9}
\label{sec:org5626e7c}
Für jede rechtslineare Grammatik G gibt es einen NFA M mit \(L(G) = L(M)\)
\subsubsection{Satz 3.13}
\label{sec:org13236f3}
Für jeden DFA M gibt es eine rechtslineare Grammatik G mit \(L(M) = L(G)\)

\subsection{3.3 NFAs mit \(\epsilon\) -Übergängen}
\label{sec:org168e181}
Grammatiken von Programmiersprachen enthalten viele Produktionen der Gestalt \(A \rightarrow B\).

Ein NFA mit \textbf{\(\epsilon\)}-Übergängen (auch \(\epsilon\) -NFA) ist ein NFA mit einem speziellen Symbol \(\epsilon \not \in \Sigma\) und mit
\(\delta : Q \times (\Sigma \cup {\epsilon}) \rightarrow P(Q)\) .
Ein \(\epsilon\) übergang darf ausgef¨uhrt werden, ohne dass ein

\subsubsection{Lemma 3.16}
\label{sec:org2ea4971}
Für jeden \(\epsilon\) -NFA \(N\) gibt es einen NFA \(N'\) mit \(L(N) = L(N')\).

\subsection{3.4 Regex}
\label{sec:org0f0bb5b}
\begin{itemize}
\item \(\emptyset\) ist ein regex
\item \(\epsilon\) ist ein regex
\item Für jedes \(a \in \Sigma\) ist a ein regulärer Audruck
\item Wenn \(\alpha\) und \(\beta\) regex dann auch
\begin{enumerate}
\item \(\alpha \beta\)
\item \(\alpha | \beta\)
\item \(\alpha^*\)
\end{enumerate}
\item Sonst NIX!
\end{itemize}
\subsubsection{Definition 3.20}
\label{sec:org8cb0869}
Zu einem regulären Ausdruck \(\gamma\) ist die zugehörige Sprache \(L(\gamma)\) rekursiv definiert:
\begin{itemize}
\item \(L(\emptyset) =\emptyset\)
\item \(L(\epsilon) = \{\epsilon\}\)
\item \(L(a) = {a}\)
\item \(L(\alpha \beta) = L(\alpha)L(\beta))\)
\item \(L(\alpha | \beta) = L(\alpha) \cup L(\beta)\)
\item \(L(\alpha^*) = L(\alpha)^*\)
\end{itemize}

\subsubsection{Satz 3.23 (Kleene 1956)}
\label{sec:org0155e6e}
Eine Sprache \(L \subseteq \Sigma^*\) ist genau dann durch einen regulären Ausdruck darstellbar, wenn sie regulär ist.\\
\smallindent
\(R^{k+1}_{ij} = R^k_{ij} \cup R^k_{i(k+1)}(R^k_{(k+1)(k+1)})^*R^k_{(k+1)j}\) \emph{in regex \(\cup = |\)}\\
\(R^{k+1}_{ij}\) = alle Wörter die in \(R^k_{ij}\) sind plus alle Wörter die mindestens einmal \(q_{k+1}\) besuchen
Somit gilt \(L(M) = L(\alpha^n_{1i_1} | ... | \alpha^n_{1i_r})\), wobei \(F=\{i_1, ..., i_r\}\)


\subsubsection{Wie teuer sind unsere Konversionen?}
\label{sec:org4de7fef}
\begin{center}
\includegraphics[width=.9\linewidth]{./img/2-kapitel/konversionen.png}
\end{center}
\begin{itemize}
\item RE \(\rightarrow \epsilon\) -NFA: RE der Länge n, \(O(n)\) Zustände
\item \(\epsilon\) -NFA \(\rightarrow\) NFA: Q
\item NFA \(\rightarrow\) DFA: \(O(2^n)\)
\item FA \(\rightarrow\) RE: \(O(n4^n)\)
\end{itemize}

\subsection{Abschlusseigenschaften regulärer Sprachen}
\label{sec:org22858fb}
\subsubsection{Satz 3.24}
\label{sec:orgf2819b8}
Seien \(R,R_1, R_2 \subseteq \Sigma^*\) reguläre Sprachen. Dann sind auch
\begin{itemize}
\item \(R_1R_2\)
\item \(R_1 \cup R_2\)
\item \(R^*\)
\item \(\bar{R} (:= \Sigma^* \backslash R)\)
\item \(R_1 \cup R_2\)
\item \(R_1 \backslash R_2\) \\
\end{itemize}
reguläre Sprachen

\begin{enumerate}
\item Produkt-Konstruktion
\label{sec:org04542ea}
Für den Schnitt ist die De-Morgan regel zu teuer also kann man auch eine Produkt Konstruktion ohne Umweg über De-Morgen benutzen.

Das funktioniert über Parallelismus also beide DFAs laufen synchron parallel (kreuzprodukt der Zustandsräume).
\end{enumerate}

\subsubsection{Satz 3.24 Abschlusseigenschaften regulärer Sprachen}
\label{sec:org8b1ee48}
Seien \(R. R_1,R_2 \subseteq \Sigma^*\) reguläre Sprachen. Dann sind auch
\(R_1R_2, R_1 \cup R_2, R^k, \bar{R} (:= \Sigma^* \backslash R), R_1 \cap R_2, R_1 \backslash R_2\) auch reguläre Sprachen

\subsubsection{Satz 3.25}
\label{sec:org7c2dd58}
Sind \(M_1 = (Q_1, \Sigma,\delta_1,s_1,F_1)\) und \(M_2 = (Q_2,\Sigma,\delta_2,s_s, F_2)\) DFAs, dann ist der \textbf{Produkt-Automat}\\
\indent\indent\indent\indent \(M := (Q_1 \times Q_2, \Sigma, \delta, (s_1,s_2), F_1 \times F_2)\) \\
\indent\indent\indent\indent \(\delta((q_1,q_2), a) := (\delta_1(q_1, a), \delta_2(q_2, a))\)

\subsection{Rechnen mit Regulären Ausdrücken}
\label{sec:orgfa39880}
\subsubsection{Definition 3.26}
\label{sec:org91fa9e4}
Zwei reguläre Ausdrücke sind \textbf{äquivalent gdw} sie die gleiche Sprache darstellen:
\(\alpha \equiv \beta: \Leftrightarrow L(\alpha) = L(\beta)\)

(by the way \(\equiv\) steht für Bedeutungsäquivalenz und \(=\) für syntaktische gleichheit)

\subsubsection{Lemma 3.27}
\label{sec:orgac15575}
\begin{itemize}
\item \(\emptyset | \alpha \equiv \alpha | \emptyset \equiv \alpha\)
\item \(\emptyset \alpha \equiv \alpha\emptyset \equiv \emptyset\)
\item \(\epsilon\alpha \equiv \alpha\epsilon \equiv \alpha\)
\item \(\emptyset^* \equiv \epsilon\)
\item \(\epsilon^* \equiv \epsilon\)
\end{itemize}

\subsubsection{Lemma 2.8}
\label{sec:org3b636a4}
\begin{itemize}
\item Assozitiviät
\item Kommutativität
\item Distributivität
\begin{itemize}
\item \(\alpha(\beta | \gamma) \equiv \alpha\beta | \alhpa\gamma\)
\item \((\alpha | \beta)\gamma \equiv \alpha\gamma | \beta\gamma\)
\end{itemize}
\item Idempotenz: \(\alpha | \alpha \equiv \alpha\)
\end{itemize}

\subsection{Pumping Lemma}
\label{sec:org806776e}
Wie zeigt man, dass eine Sprache nicht regulär ist?
\subsubsection{Satz 3.32 (Pumping Lemma für Reguläre Sprachen)}
\label{sec:orge937547}
Sei \(R \subseteq \Sigma^*\) regulär. Dann gibt es ein \(n > 0\), so dass sich jedes \(z \in R\) mit \(|z| \geq n\) so in \(z = uvw\) zerlegen lässt, dass
\begin{itemize}
\item \(v \neq \epsilon\),
\item \(|uv| \leq n\)
\item \(\forall i \geq 0. uv^iw \in R\). \\
\end{itemize}

Es gibt nicht-reguläre Sprachen, für die das Pumping-Lemma gilt!
\(\Rightarrow\) Pumping-Lemma hinreichend aber nicht notwendig um Nicht-Regularität zu zeigen.

regulär  \(\subset\) Pumping-Lemma gilt \(\subset\) alle Sprachen

\subsection{Entscheidungsverfahren}
\label{sec:org684ea1d}

\textbf{Eingabe:} Ein oder mehrere Objekte, die Reguläre Sprachen beschreiben (DFA, NFA, RE Typ3 Gram, \ldots{})
\textbf{Frage:} Haben die Sprachen die Eigenschaft X?
Ein (Entscheidungs-)Problem ist entscheidbar, wenn es einen Algorithmus gibt, der bei jeder Eingabe in endlicher Zeit die richtige Antwort auf die Frage feststellt.

Welche Entscheidungsprobleme sind für rechtslineare Grammatiken entscheidbar und wie hängt die Laufzeit mit der Beschreibung zusammen.

\subsubsection{Definition 3.37}
\label{sec:orgaf9165b}
Sei D ein DFA, NFA, RE, rechtslineare Grammatik \ldots{}
\begin{itemize}
\item \textbf{Wortproblem}: Gegeben \(w\) und D: gilt \(w \in L(D)\)
\item \textbf{Leerheitsproblem}: Gegeben D: gilt \(\emptyset = L(D)\)
\item \textbf{Endlichkeitsproblem}: Gegeben D: isz \(L(D)\) endlich
\item \textbf{Äquivalenzproblem}: Gegeben \(D_1, D_2\), gilt \(L(D_1) = L(D_2)\)
\end{itemize}

\subsection{Automaten und Gleichungssysteme}
\label{sec:orgc5a58df}
Wir werden jetzt aus einem Automat ein Gleichungssystem machen um daraus einen RE zu machen.

\subsubsection{Ardens Lemma (Satz 3.47)}
\label{sec:orga67431f}
Sind A, B und X Sprachen mit \(\epsilon \not \in A\), so gilt
\(X = AX \cup B \Rightarrow X = A^*B\)
\subsubsection{Korollar 3.48}
\label{sec:org8285997}
Sind \(\alpha, \beta\) und X reguläre Ausdrücke mit \(\epsilon \not \in L(\alpha)\), so gilt
\(X \equiv  \alpha X|\beta \Rightarrow X \equiv \alpha^*\beta\)
\subsubsection{Algorithmus um RE aus Automat zu machen}
\label{sec:orgd96c06d}

\begin{enumerate}
\item Wandle FA mit n Zuständen in ein System von n Gleichungen
\item Löse das System durch schrittweise Elimination von Variablen mit Hilfe von Ardens Lemma für REs (Korollar 3.48).
\item Ist k der Startzustand, so beschreibt X\textsubscript{k} die vom Automaten akzeptierte Sprache.
\end{enumerate}

\subsection{Minimierung endlicher Automaten}
\label{sec:org771cca6}
\textbf{TODO MIA}

\subsection{Äquivalenztest von DFAs}
\label{sec:org3beca56}
Zwei Automaten sind genau äquivalent wenn:
\begin{enumerate}
\item Gegeben DFAs \(M1\) und \(M2\), bilde disjunkte Vereiningung. \\
(”Male M1 und M2 nebeneinander.“)
\item Berechne Menge der äquivalenten Zustände.
\item L(M1) = L(M2) gdw die beiden Startzustände äquivalent sind
\end{enumerate}

\subsection{Äquivalenz von Zuständen}
\label{sec:orgf53c5cf}
Zwei Zustände sind äquivalent wenn sie selbe Sprache akzeptieren.


\subsection{Minimalität des Quotientenautomaten}
\label{sec:org6801741}

Die Residualsprache von L bzgl \(w \in \Sigma^*\) ist die Menge:

\(L^w := \{z \in \Sigma^* | wz \in L\}\)

\(L' \subseteq \Sigma^*\) ist Residualsprache von L wenn es \(w\) gibt mit \(L' = L^w\)

\subsubsection{Definition 3.55 (Äquivalenz von Wörtern bzgl. L)}
\label{sec:orgcb86de7}
(Intuition: Zwei Wörter sind äquivalent wenn sie die gleiche Residualsprache haben.)

\textbf{zwei Wörter sind äquivalent gdw sie zu den gleichen Zuständen führen}

\subsubsection{Satz 3.56}
\label{sec:orgf87bb5e}
Sei M ein DFA ohne unerreichbare Zustände. Der Quotientenautomat \(M / \equiv\) ist ein minimaler DFA für \(L(M)\).

\subsection{Definition 3.57 (Kanonischer Minimalautomat)}
\label{sec:org3620a57}
\(M_L := (R_L, \Sigma, \delta_L, L, F_L)\)
mit \(\delta_L(R, a) := R^a\) und \(F_L := {R \in RL | \varepsilon \in R}\).
\(\delta_L\) ist wohldefiniert und \(\hat{\delta}}_L(R, w) = R^w\). Jeder Zustand \(R\) erkennt
die Sprache \(R\) und somit \(L(M_L) = L\).
\subsubsection{Satz 3.58}
\label{sec:orgf282936}
Jeder minimaler DFA für eine reguläre Sprache L unterscheidet sich vom kanonischen Minimalautomaten M\textsubscript{L} nur durch eine
\subsection{Satz 3.59}
\label{sec:org6fcd8b1}
Eine Sprache \(L \subseteq \Sigma^*\) ist genau dann regulär, wenn sie endlich viele Residualsprachen hat.

\section{Kontextfreie Sprachen}
\label{sec:org0d32185}
\subsubsection{Syntaxbaum:}
\label{sec:orgb2de9dc}
Die Blätter des Baums, von links nach rechts gelesen,
\subsection{Definition 4.2}
\label{sec:org8e61692}
Eine kontextfreie Grammatik \(G = (V, \Sigma, P, S)\) ist ein 4-Tupel: \\
\(V\) ist eine endlichen Menge, die Nichtterminalzeichen (oder Variablen), \\
\(\Sigma\) ist ein Alphabet, die Terminalzeichen, disjunkt von V ,
\(P \subseteq V \times (V \cup Σ´\Sigma)*\) eine endlichen Menge, die Produktionen, und \\
\(S \in V\) ist das Startsymbol.
\subsection{Definition 4.4}
\label{sec:orge284ae1}
Eine kontextfreie Grammatik G = (V, Σ, P, S) induziert eine
Ableitungsrelation →G auf W¨ortern ¨uber V ∪ Σ:
α →G β
gdw es eine Regel A → γ in P gibt, und W¨orter α1, α2, so dass
α = α1Aα2
und
β = α1γα2
Beispiel:
a + T + a
→G

\subsection{Definition 4.5 (Reflexiv transitive Hülle)}
\label{sec:orgc2f2782}
TODO

\subsection{Definition 4.6 (Kontextfreie Sprache)}
\label{sec:org87fed7e}
TODO

\subsection{Lemma 4.9 (Dekompositionslemma)}
\label{sec:orgc7c5040}
\(\alpha_1 \alpha_2 \rightarrow^n_G \beta\) \\
\(\Leftrightarrow\) \\
\(\exists \beta_1, \beta_2, n_1, n_2. \beta = \beta_1\beta_2 \land n = n_1 + n_2 \land \alpha_i \rightarrow^{n_i}_G \beta_i (i = 1, 2)\)

\subsection{Definition 4.12 (Balancierte Klammerausdrücke)}
\label{sec:org148599b}
\subsubsection{Präfix}
\label{sec:orgc207bb6}
\(u \preceq w \iff \exists v : uv = w\)
\subsubsection{Anzahl an Vorkommnissen}
\label{sec:org5c74967}
\(\#_a(w) :=\) Anzahl an \(a\)'s in \(w\)
Seien \(A(w) := \#_[(w) \quad B(w) := \#_](w)\)
\(w\in \{\ [\ ,\ ]\ \}^*\) sei \textbf{balanciert} gdw
\begin{enumerate}
\item \(A(w) = B(w)\)
\item \(\forall u \preceq w : A(u) \geq B(u)\)
\end{enumerate}
\subsubsection{4,13}
\label{sec:org1182d95}
Grammatik \(S \rightarrow \epsilon\ |\ [S]\ |\ SS\) erzeugt genau die Menge der balancierten Wörter

\subsection{4.15 Syntaxbaum}
\label{sec:org13cc0ad}
Ein Syntaxbaum für \(G = \{V, \Sigma, P, S)\}\) so dass gilt:
\begin{itemize}
\item jedes Blatt mit einem Zeichen aus \(\Sigma \cup \{\epsilon\}\) beschriftet ist
\item jeder innere Knoten mit einem \(A\in V\) beschriftet ist, falls Nachfolger: als \(X_1, ..., X_n \in V\cup \Sigma \cup \{\epsilon\}\) beschriftet. Dann ist \(A \rightarrow X_1, ..., X_n\) eine Produktion in \(P\)
\item ein Blatt \(\epsilon\) der einzige Nachfolger seines Vorgänger ist
\end{itemize}

\subsection{4.17 Äquivalente Bedingungen}
\label{sec:orgb916d92}
Für ein CFG \& \(w \in \Sigma^*\)
\begin{itemize}
\item \(A\rightarrow_G^* w\)
\item \(w\in L_G(A)\) (gemäß der induktiven Definition)
\item Es gibt ein Syntaxbaum mit Wurzel A dessen \textbf{Rand} das Wort \emph{w} ist
\end{itemize}

\subsection{4.18}
\label{sec:org9f9d39d}
Ein CFG heißt mehrdeutig \(\iff\) es 2 \textbf{verschiedene} Syntaxbäume gibt die mit gleichem Rand \\
Ein CFL L heißt inhärent mehrdeutig \(\iff\) jede CFG G mit \(L(G) = L\) mehrdeutig ist

\section{Chomsky-Normalform}
\label{sec:orgd9a2aa7}
\subsubsection{4.21}
\label{sec:org05b032d}
Ein CFG G ist in Chomsky-Normalform \(\iff\) alle Produktionen eine der Formen:
\(\qquad A \rightarrow a\quad\) oder \(\quad A\rightarrow BC\quad\) haben
\subsubsection{4.22}
\label{sec:org4f81294}
Jede CFG G hat eine CFG \(G'\) in Chomsky-Normalform mit \(L(G') = L(G) \backslash \{\epsilon\}\)
Wenn man \(\epsilon \in L(G')\) haben will: Füge am Ende \(S' \rightarrow S, S\rightarrow \epsilon\) hinzu und setzte \(S'\) als Startsymbol

\subsubsection{Beispiel mit Farben weil Noah immernoch nicht versteht}
\label{sec:orgd62b54c}
\begin{center}
\includegraphics[width=.9\linewidth]{./img/3-kapitel/chomskybsp.png}
\end{center}

\(A\rightarrow B\) ist eine \textbf{Kettenproduktion}
\subsection{4.25}
\label{sec:orgd045c46}
Aus jeder CFG G kann man ein CFG G' konstruieren was keine Kettenproduktionen enthält sodass gilt \$L(G) = L(G')

\subsubsection{Beispiel Kettenproduktionen:}
\label{sec:org8bc154f}
\begin{center}
\includegraphics[width=.9\linewidth]{./img/3-kapitel/chomskybsp2.png}
\end{center}

\subsection{Konstruktion einer Chomsky-Normalform}
\label{sec:org1805ef7}
Eingabe: eine kontextfreie Grammatik \(G = (V, \Sigma, P, S)\)
\begin{enumerate}
\item Für jedes \(a\in \Sigma\) das in einer Produktion mit Länge \(\ge\) 2 vorkommt:
\begin{itemize}
\item Füge ein neues Nichtterminal \(X_a\) zu \(V\) \& ersetzt alle diese a's dadurch
\item Füge \(X_a \rightarrow a\) zu \(P\) hinzu
\end{itemize}
\item Ersetze Produktion in der Form: \\
\begin{center}
\(A\rightarrow B_1B_2...B_k\quad (k\ge 3)\)
\end{center}
durch \\
\begin{center}
\(A\rightarrow B_1C_2,\ C_2\rightarrow B_2C_3,\ ...,\ C_{k-1}\rightarrow B_{k-1}B_k\) \\
\end{center}
wobei \(C_2,\ ...,\ C_{k-1}\) neue Nichtterminale sind
\item Elimniere alle \(\epsilon\) -Produktionen
\item Eliminiere alle Kettenproduktionen
\end{enumerate}

\subsection{4.27 Greibach-Normalform}
\label{sec:org463ef91}
Ein CFG ist in Greibach-Normalform falls alle Produktionen in der From sind: \\
\(A\rightarrow aA_1...A_n\)

\subsubsection{Satz 4.28}
\label{sec:orgcb08794}
Zu jeder CFG G gibt es eine CFG \(G′\) in Greibach-Normalform mit \\
\(L(G') = L(G) \backslash \{\epsilon\}\).

\subsection{Pumping Lemma für kontextfreie Sprachen}
\label{sec:org937e185}
Für jede kontextfreie Sprache L gibt es ein \(n \ge 1\), so dass sich jedes Wort \(z\in L\) mit \(|z| \ge n\) sich zerlegen lässt in: \\
\(z = uvwxy\) \\
mit
\begin{itemize}
\item \(vx \ne \epsilon\)
\item \(|vwx| \le n\)
\item \(\forall i \in \mathbb{N} : uv^iwx^iy\in L\)
\end{itemize}

\subsection{Abschlusseigenschaften kontextfreie Sprachen}
\label{sec:orgae09195}
Die Klasse der kontextfreien Sprachen ist also unter Vereinigung, Konkatenation, Stern und Spiegelung abgeschlossen. (Genau wie reguläre Sprachen)
\subsection{Algorithmen für kontextfreie Grammatiken}
\label{sec:org2657741}
\(G\) sei eine CFG
Ein Symbol \(X \in V \cup \Sigma\) ist
\begin{itemize}
\item \textbf{nützlich} gdw es eine Ableitung \(S \rightarrow^*_G w \in \Sigma^*\) gibt in der \(X\) vorkommt.
\item \textbf{erzeugend} gdw es eine Ableitung X \(\rightarrow\)\textsuperscript{*}\textsubscript{G} w \(\in\) \(\Sigma\)\textsuperscript{*}\$ gibt.
\item \textbf{erreichbar} gdw es eine Ableitung \(S \rightarrow^*_G \alpha X \beta\)
\end{itemize}
\subsubsection{Satz 4.36}
\label{sec:org9e31004}
Eliminiert man aus einer Grammatik \(G\)
\begin{enumerate}
\item alle nicht erzeugenden Symbole, mit Resultat \(G_1\), und
\item aus \(G_1\) alle unerreichbaren Symbole, mit Resultat \(G_2\),
\end{enumerate}

dann enthält \(G_2\) nur noch nützliche Symbole und \(L(G_2) = L(G)\).

\subsubsection{Satz 4.37}
\label{sec:org7ef5ef0}
Die Menge der erzeugenden Symbole einer CFG sind berechenbar
\subsubsection{Satz 4.38}
\label{sec:orgbd1321b}
Für eine CFG ist entscheidbar, ob \(L(G) = \emptyset\)
\subsubsection{Satz 4.40}
\label{sec:org63e69c7}
Die Menge der erreichbaren Symbole einer CFG ist berechenbar.

\subsection{Der Cocke-Younger-Kasami-Algorithmus}
\label{sec:org5cb18ef}
Der CYK-Algorithmus entscheidet das Wortproblem für kontextfreie Grammatiken in Chomsky-Normalform.
Eingabe: Grammatik in Chomsky-Normalform,
\(w = a_1 ... a_n \in \Sigma^*\)
\subsubsection{Definition 4.42}
\label{sec:org427ead6}
V\textsubscript{ij} := \{A \(\in\) V | A \(\rightarrow\)\textsuperscript{*}\textsubscript{G} a\textsubscript{i\ldots{}a}\textsubscript{j}\$ für \(i \geq j\) \\
Damit gilt: \\
\(w \in L(G) \iff S \in V_{1n}\)
\subsubsection{Satz 4.44}
\label{sec:org9c29fa6}
Der CYK-Algorithmus entscheidet das Wortproblem \(w \in L(G)\) für eine fixe CFG G in Chomsky-Normalform in Zeit \(O(|w|^3)\).

\subsubsection{Vorschau}
\label{sec:orga88137d}
Für CFGs sind folgende Probleme nicht entscheidbar:
\begin{itemize}
\item Äquivalenz: \(L(G_1) = L(G_2)\)?
\item Schnittproblem: \(L(G_1) \cap L(G_2) = \emptyset\)?
\item Regularität: \(L(G)\) regulär?
\item Mehrdeutigkeit: Ist \(G\) mehrdeutig?
\end{itemize}
\end{document}
